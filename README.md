# ReportShield
**ReportShield startup tech company **

**Item 1**

**1.A. Company Name** Report Shield is a startup tech company that acts as an anonymous reporting tool that will allow users to securely report fake social media accounts being created,
cyberbullying, and harmful content without having the fear of retaliation. The platform provides users with an anonymous, secure, and efficient way to report any digital or online threats while completely integrateding with any major social media platform. ReportShield prioritizes the safety, privacy, and ethical responsibility of all users and the platform itself. 

**1.B. Long-Term Vision Statement** 
**1.B.1. Goals:** The primary goal of reportshield is to create a digital safespace accross all social media platforms. To provide users with a digital Utopia free from any fear of ridicule, judgement, or discrimination. This can be acheived by providing users with secure, anonymous, and accessible platforms to report harmful online activities. By integrating with major social media platforms like; Instagram, TikTok, X, Snapchat, Facebook, etc. ReportSheild aims to if not eradicate then reduce the widespread pervasiveness of cybebullying, creation of fraudulent accounts, and the spread of harmfu content.

**1.B.2. Idea Organization:** The idea for reporsheild originated as an idea to research focusing on cyberbullying and social media exploitation. With the rise of bot accounts, fake acounts, online harasment, and digital misinformation hghlights a tremendous need to provide all users with a veil of safety the the use of an anonymous and userfriendly reporting tool. This idea was inspiried by the 2006 court case United States vs. Lori Drew. Where a mother and daughter posed as a fake account to harass a 13 year old girl so much to the point that it drove the 13 year old girl to take her own life. Reportsheild was developed to empower all its users so as that they may not face the same harm as the victim in the aforementioned court case. 

**1.B.3. Purpose/Values/Mission:** The purpose of this start up is to create a safer digital world. A digital Utopia free from any harm by empowring users with the ability to anonymously report any harmful online behavior free from any fear of retaliation. Our values include privacy, security, trasnparency, and ethical responsibility. Privacy to ensure that users can report annonymously withouth fear of retaliation. Security is the data encryption that secures unauthoried access to your reporting information. Transparency allows for users to recieve updates on report outcomes ensuring a high trust relationship beingtween our users and the system. Ethical responsibility promotes the idea of a saespcae in any social media platfrom that Report  Sheild partners with and prioritizes ethical decision making in our operations. 

**1.B.4. Key Questions:**
How can maximum anonymity for the victims be ensured whle maintiaining maximum accountability for the perpetrators of cyberbullying or harassment?
What technologies can be implemented t make reporting easier and more effective for diverse users such as those whom are disabled?
How do we balance freedom of speech and the policies of each social media company with the need to remove harmful content online?

**1.C.1.1 OKR 1 Objective and Key Result** 
**Objective:**
Ensure Report Shield gives anonymous accessible and an efficient reporting system. When it comes to cyberbullying, spam, bot accounts, and harmful content across major social media platforms. This content could be; graphic, sexually explicit, or hate speech.
**Key Result:**
Conduct usability study with 1,000 users from diverse demographics. The targeted rate of user satisfaction should be 90%. Report Shield must be easy to use, it ought to provide the user anonymity as well.

**Stake Holders:**
**Users:**
The main userbase foe the study will be the main userbase of social media teens and young adults aged 13-30. They must be of diverse race as well as gender. There should be no minimum or cap on their income level. Their sexual orientation should also be diverse as cyberbullying can target those of differing races, genders, or sexual orientations thus it’s encouraged that these demographics be diverse. They also use social media often throughout their day. They use it for entertainment, education, networking, and for a professional setting.
**Social Media Platforms:**
These companies benefit from reducing harmful content on their platforms. This will improve the safety of their users. Which in turn will raise their user retention and compliance with their company guidelines. Their platforms will also make more money due to more advertisers willing to promote their products on these platforms due to a reduction in explicit content.
**Law Enforcement:**
Police agencies can use verified reports from the social media platforms and the encrypted evidence from Report Sheild to launch investigations against those who perpetrate these crimes. This will also ensure the privacy of the victims of the cybercrimes to ensure they don't suffer from retaliation from the cybercriminals. It is to also ensure the privacy of the law enforcement officers so as to not alert the cybercriminal of their investigation.
**Mental Health Advocates:**
Organizations that focus on mental health can use Report Sheild’s data to spread awareness and even assist in user policy in social media platforms or in Report Sheild. Families and Caretakers of the Victim:
Parents and guardians could use Report Sheild to educate young users about online safety and intervene if cyberbullying were to ever occur.

**1.C.1.2 OKR 1 Metric(s) with Experiment(s)** 
**2.) Metrics and experiments:**
To attain 90% user satisfaction rate. Report Sheild will conduct a usability study with 1,000 participants from diverse demographics. The study will involve a survey and observing the participants interacting with the Report Shield platform.
**Metrics:**
User satisfaction score on survey:
Sample questions:
“On a scale of 1-10, how satisfied are you with the ease of reporting the issue?”
“On a scale of 1-10, how secure did you feel in your anonymity when using Report Sheild?”
“On a scale of 1-10, how likely are you to recommend Report Sheild to others?
Success metric: 90% of users report the average of the survey as 8/10 or higher.
Task Completion Rate:
Users must successfully complete a report in 5 minutes.
Success Metric: 90% of users can complete said task in 5 minutes.
Error Rate:
Tracks how many users make errors (incorrect submissions).
Success Metric: Error rate is below 10%.
Retention Rate:
Measures how many users continue to use Report Sheild after 3 months.
Success Metric: At least 70% of participants use Report Sheild after 3 months.
**Experiments:**
A/B Testing:
2 different UI designs will be tested to see which layout is more engaging to the user by
measuring the task completion rate on both UIs.
Usability Testing:
Users will be asked to submit a report while usability experts observe any
challenges or bugs occurring in this process.
Follow up survey:
Every month participants will be given a survey to check their user satisfaction as well as
if they had used it in the last month and 3 will be given out at the end of each month up
until the end of the 3rd month.

**1.C.1.3 OKR 1 Ethical Impact(s)/Issue(s)**
3.) Ethical Impacts & Issues
While report shield ensures safety for the users and the social media platforms. It also introduces
ethical concerns, particularly around privacy, misuse, and data security. false accusations or
misuse
Potential Ethical & Real-World Issues
Privacy Risks: Anonymous reporting raises concerns about false accusations and misuse.
Case Study: The misuse Twitter’s reporting system, where false mass reports have led to wrongful account suspensions.
Conflicting interests: Social media companies might be reluctant to integrate Report Shield if it increases their content moderation burden.
Potential for Bias: If the usability test doesn’t include a diverse range of participants, the platform’s effectiveness may be skewed toward certain demographics. Thus it could lead to forms of discrimination as it can target certain demographics more harshly for reports of cybercrimes falsely.


Ethical impact Risk Table:
Stakeholder            | Financial Risk | Privacy Risk | Conflicting Interest | Violation of Rights ||
------------------------------------------------------------------------------------------------------
Users                  | Low            | High         | Mid                  | Mid                 ||
------------------------------------------------------------------------------------------------------
Social Media Platforms | Mild           | Low          | High                 | Mid                 ||
------------------------------------------------------------------------------------------------------
Law Enforcement        | Mild           | Low          | Mid                  | High                ||
------------------------------------------------------------------------------------------------------
Advocacy Groups        | Low            | Low          | Low                  | None                ||
------------------------------------------------------------------------------------------------------
Families & Caretakers  | Low            | Mid          | Low                  | None                ||
------------------------------------------------------------------------------------------------------


Analysis of Ethical Risks:
Uses (High Privacy Risk): Since reports are anonymous, if the encryption fails then the user’s identity will be vulnerable to theft.
Law Enforcement (High Violation of Rights Risk): If reports have misinformation or are outright false then it could lead to wrongful arrests.
Social Media Platforms (High Conflicting Interest Risk): The platforms may have to pay extra for the use of report shield and in content moderation.

**1.C.1.4 OKR 1 Ethical Safeguards**
To reduce risk Report Sheild will implement these ethical safeguards.
1). Data Encryption & Privacy Protection
End-To-End Encryption: Report Sheild will use encryption to ensure reports are anonymous.
Anonymous reporting: No personal information is stored by the program ensuring the report is anonymous.
2). False Report Prevention System:
Reports flagged as spam or harmful will be viewed by human moderators before being sent to platforms or law enforcement.
3). Bias Free Usability Testing
The 1,000 test users will be selected from all genders, races, ages, sexual orientations to ensure diversity and inclusivity.
4). Oversight
Report Sheild ethics board will be established it will have:
- Cybersecurity professionals
- Advocacy group representatives for mental health and cyberbullying organizations
- Social media company representatives.
Measuring Effectiveness
Audit Logs: Regular auditsensure encrypted data remains safe and unexposed.
User Feedback Surveys: Continual collection of user input regarding experience, engagement, privacy, and safety.
Independent Evaluations: Cybersecurity firms to review Report Sheild’s practices on a quarterly basis.

**1.C.2.1 OKR 2 Objective and Key Result**
**1.C.2.2 OKR 2 Metric(s) with Experiment(s)**
**1.C.2.3 OKR 2 Ethical Impact(s)/Issue(s)**
**1.C.2.4 OKR 2 Ethical Safeguards**
**1.C.3.1 OKR 3 Objective and Key Result**
**1.C.3.2 OKR 3 Metric(s) with Experiment(s)**
**1.C.3.3 OKR 3 Ethical Impact(s)/Issue(s)**
**1.C.3.4 OKR 3 Ethical Safeguards**
